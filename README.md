# Sistema Inteligente de Auditor√≠a de Facturas y Dimensiones

Una aplicaci√≥n web para validar autom√°ticamente los totales de las facturas de env√≠o contra sus CSV de respaldo y verificar las dimensiones de los productos utilizando IA, registrando las discrepancias en una base de datos en la nube.

## Descripci√≥n General üßæ

En la log√≠stica, es com√∫n que las facturas de env√≠o contengan errores, ya sea en el total facturado o en las dimensiones y pesos de los paquetes (peso aforado), lo que genera sobrecostos. Este proyecto automatiza el proceso de auditor√≠a.

La aplicaci√≥n permite a un usuario cargar un archivo de factura y su CSV correspondiente. El sistema realiza dos validaciones clave:

1.  **Validaci√≥n de Totales:** Compara el total monetario de la factura con la suma de las tarifas en el archivo CSV.
2.  **Validaci√≥n de Dimensiones:** Para cada producto en el CSV, utiliza la API de Tavily para buscar en la web y la API de Gemini para extraer las dimensiones y peso reales del producto. Luego, compara estos datos con los informados en el CSV.

Todas las discrepancias encontradas se registran en una tabla `scales` en una base de datos Google Cloud SQL, creando un registro auditable. La interfaz est√° construida con Streamlit y est√° dise√±ada para ser desplegada en Google Cloud Run.

## üöÄ Features

* **Interfaz Interactiva:** Carga de archivos de factura y CSV directamente desde el navegador.
* **Auditor√≠a de Totales:** Verificaci√≥n autom√°tica del total de la factura contra los datos del CSV.
* **Verificaci√≥n con IA:** B√∫squeda web inteligente para encontrar dimensiones y pesos de productos.
* **C√°lculo de Discrepancias:** Identifica y calcula las diferencias entre los datos informados y los datos reales.
* **Registro en Base de Datos:** Almacena de forma persistente todas las discrepancias encontradas en Cloud SQL.
* **Escalable y Serverless:** Desplegado en Cloud Run para una gesti√≥n sin servidores y escalado autom√°tico.

## üõ†Ô∏è Arquitectura y Tech Stack

El proyecto utiliza una arquitectura moderna serverless para procesar los datos de manera eficiente.

* **Frontend:** Streamlit
* **Backend & L√≥gica:** Python
* **Base de Datos:** Google Cloud SQL (MySQL)
* **B√∫squeda Web:** Tavily API
* **Extracci√≥n de Datos (IA):** Google Gemini API (Vertex AI)
* **Hosting:** Google Cloud Run
* **Almacenamiento de Archivos:** Google Cloud Storage
* **Contenerizaci√≥n:** Docker
* **Flujo de Datos:** Usuario ‚Üí Streamlit UI (Cloud Run) ‚Üí Backend Python ‚Üí (Tavily/Gemini APIs) & (Cloud SQL / Cloud Storage)

## üóÑÔ∏è Esquema de la Base de Datos

La base de datos contiene principalmente tres tablas:

* **`invoices`**: Almacena la informaci√≥n de cada env√≠o o l√≠nea del CSV.
* **`tarifario`**: Contiene las reglas de precios y tarifas.
* **`scales`**: Registra los resultados de la verificaci√≥n de dimensiones. Cada fila tiene una `ForeignKey` al `id` de la tabla `invoices`, vinculando la discrepancia con el env√≠o espec√≠fico.

---

## ‚öôÔ∏è Ejecuci√≥n en Entorno Local

Para ejecutar la aplicaci√≥n en tu m√°quina mientras te conectas a los servicios de Google Cloud, sigue estos pasos:

1.  **Clonar el Repositorio**
    ```bash
    git clone [https://github.com/BJRomPal/llmops2025.git](https://github.com/BJRomPal/llmops2025.git)
    cd llmops2025
    ```

2.  **Configurar Entorno Virtual y Dependencias**
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

3.  **Configurar Google Cloud Platform (GCP)**
    * Crea un nuevo proyecto en la [Consola de GCP](https://console.cloud.google.com/).
    * Habilita las APIs necesarias: **Cloud SQL Admin API**, **Vertex AI API**, y **Cloud Storage API**.
    * **Cloud SQL:** Crea una instancia de MySQL y una base de datos. Anota el **nombre de conexi√≥n de la instancia**, crea un **usuario** y una **contrase√±a**.
    * **Cloud Storage:** Crea un bucket. Anota el **nombre del bucket**.
    * **Permisos:** Aseg√∫rate de que tu cuenta de usuario en IAM tenga los roles necesarios para administrar estos servicios (ej. `Editor` o roles espec√≠ficos como `Administrador de Cloud SQL`, `Administrador de Storage`).

4.  **Generar Claves de API**
    * **Gemini API:** Genera tu clave de API desde la consola de Vertex AI o Google AI Studio.
    * **Tavily API:** Obt√©n tu clave de API desde el [sitio web de Tavily](https://tavily.com/).

5.  **Crear el archivo `.env`**
    En la ra√≠z del proyecto, crea un archivo llamado `.env` y ll√©nalo con tus credenciales. Usa el siguiente formato:
    ```env
    GOOGLE_CLOUD_PROJECT="tu-id-de-proyecto-gcp"
    DB_USER="tu-usuario-de-base-de-datos"
    DB_PASSWORD="tu-contrase√±a-de-base-de-datos"
    DB_NAME="el-nombre-de-tu-base-de-datos"
    INSTANCE_CONNECTION_NAME="proyecto:region:instancia"
    BUCKET_NAME="el-nombre-de-tu-bucket"
    GOOGLE_API_KEY="tu-api-key-de-gemini"
    TAVILY_API_KEY="tu-api-key-de-tavily"
    ```

6.  **Autenticar tu M√°quina Local**
    Para que tu aplicaci√≥n local pueda acceder a los servicios de GCP (Cloud SQL, Cloud Storage), autentica tu SDK de `gcloud`:
    ```bash
    gcloud auth application-default login
    ```
    Este comando abrir√° un navegador para que inicies sesi√≥n con tu cuenta de Google. Tu cuenta debe tener permisos de **Cliente de Cloud SQL** y **Administrador de objetos de Storage**.

7.  **Ejecutar la Aplicaci√≥n**
    ¬°Ya est√° todo listo! Inicia la aplicaci√≥n Streamlit:
    ```bash
    streamlit run app.py
    ```

---

## ‚òÅÔ∏è Despliegue en Google Cloud Run

Este es el proceso para empaquetar la aplicaci√≥n en un contenedor y desplegarla como un servicio serverless.

1.  **Habilitar APIs en GCP**
    Aseg√∫rate de que las siguientes APIs est√©n habilitadas en tu proyecto: **Cloud Run API**, **Artifact Registry API**, **Secret Manager API** y **Cloud Build API**.

2.  **Guardar Secretos en Secret Manager**
    Por seguridad, nunca expongas tus credenciales directamente. Gu√°rdalas en Secret Manager:
    * `GOOGLE_API_KEY`
    * `TAVILY_API_KEY`
    * `DB_USER`
    * `DB_PASSWORD`
    * Crea un secreto para cada una de estas claves. Por ejemplo:
        ```bash
        printf "tu-contrase√±a-de-base-de-datos" | gcloud secrets versions add llmops-db-password --data-file=-
        ```

3.  **Construir y Subir la Imagen de Docker**
    * **Crear Repositorio:** Primero, crea un repositorio en Artifact Registry para almacenar tu imagen.
        ```bash
        gcloud artifacts repositories create llmops2025 --repository-format=docker --location=us-central1
        ```
    * **Autenticar Docker:** Configura Docker para que pueda conectarse a Artifact Registry.
        ```bash
        gcloud auth configure-docker us-central1-docker.pkg.dev
        ```
    * **Construir la Imagen:** Desde la ra√≠z de tu proyecto (donde est√° el `Dockerfile`), ejecuta:
        ```bash
        docker build -t us-central1-docker.pkg.dev/tu-id-de-proyecto-gcp/llmops2025/analizador-facturas .
        ```
    * **Subir la Imagen:**
        ```bash
        docker push us-central1-docker.pkg.dev/tu-id-de-proyecto-gcp/llmops2025/analizador-facturas
        ```

4.  **Desplegar el Servicio en Cloud Run**
    Ejecuta el siguiente comando para desplegar tu aplicaci√≥n. Este comando conecta el servicio a Cloud SQL, inyecta las variables de configuraci√≥n y los secretos, y asigna los permisos necesarios.

    * **Permisos:** Antes de desplegar, aseg√∫rate de que la **cuenta de servicio de Compute Engine por defecto** (`NUMERO-PROYECTO-compute@developer.gserviceaccount.com`) tenga los siguientes roles en IAM:
        * `Cliente de Cloud SQL`
        * `Accesor de secretos de Secret Manager`
        * `Administrador de objetos de Storage`

    * **Comando de Despliegue:**
        ```bash
        gcloud run deploy analizador-facturas \
            --image us-central1-docker.pkg.dev/tu-id-de-proyecto-gcp/llmops2025/analizador-facturas \
            --platform managed \
            --region us-central1 \
            --allow-unauthenticated \
            --set-env-vars="GOOGLE_CLOUD_PROJECT=tu-id-de-proyecto-gcp,DB_NAME=el-nombre-de-tu-base-de-datos,INSTANCE_CONNECTION_NAME=proyecto:region:instancia,BUCKET_NAME=el-nombre-de-tu-bucket" \
            --set-secrets="GOOGLE_API_KEY=llmops-google-api-key:latest,TAVILY_API_KEY=llmops-tavily-api-key:latest,DB_USER=llmops-db-user:latest,DB_PASSWORD=llmops-db-password:latest"
        ```

    Una vez finalizado el despliegue, `gcloud` te proporcionar√° la URL p√∫blica de tu aplicaci√≥n.
